{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264f4f89",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7a67804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:52.497644Z",
     "start_time": "2025-11-23T14:44:51.727050Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "d1b9321a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:52.510984Z",
     "start_time": "2025-11-23T14:44:52.508734Z"
    }
   },
   "source": [
    "all_format = [\"Basic\",\"Sequential\", \"Encoded\", \"Wide\"]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e7aa5fbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:52.529884Z",
     "start_time": "2025-11-23T14:44:52.518275Z"
    }
   },
   "source": [
    "class TransactionDf():\n",
    "\n",
    "    def __init__(self,file_path,header=False,target_column=None,separator=\",\",formatting=\"Basic\"):\n",
    "        self.file_paths = [file_path]\n",
    "        self.headers = [header]\n",
    "        self.target_columns = [target_column]\n",
    "        self.separators = [separator]\n",
    "        self.dfs = []\n",
    "        self.load_transactions(file_path,header=header,target_column=target_column,sep=separator,formatting=formatting)\n",
    "    \n",
    "    def load_transaction_csv(self,file_path,header,target_column,sep,formatting):\n",
    "        if header:\n",
    "            transactions = pd.read_csv(file_path)\n",
    "        else :\n",
    "            transactions = pd.read_csv(file_path,header=None)\n",
    "        \n",
    "        if formatting == \"Wide\":\n",
    "            #   transaction_id, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "            #   items, \"bread,milk,eggs\", \"bread,butter\", ...\n",
    "            formatting = \"Basic\"\n",
    "            transactions = transactions.T\n",
    "\n",
    "        if formatting == \"Basic\":\n",
    "            #   transaction_id,items\n",
    "            #   1,\"bread,milk,eggs\"\n",
    "            #   2,\"bread,butter\"\n",
    "\n",
    "            # check if there is a transaction_id column\n",
    "            if len(transactions.columns) == 1:\n",
    "                target_column = transactions.columns[0]\n",
    "            elif target_column not in transactions.columns:\n",
    "                raise ValueError(f\"the targeted column {target_column} is not in {transactions.columns}\")\n",
    "            if sep:\n",
    "                transactions = transactions[transactions[target_column].apply(lambda x: isinstance(x, str))]\n",
    "                transactions[target_column] = transactions[target_column].apply(lambda x: [i.strip() for i in x.split(\",\")])\n",
    "            \n",
    "\n",
    "            # all this hot encode a column and keep all the others column\n",
    "            transactions_exploded = transactions[target_column].explode()\n",
    "\n",
    "            transactions_dummies = pd.get_dummies(transactions_exploded)\n",
    "\n",
    "            #0_ in order to make a sequential feature\n",
    "            transactions_dummies.columns = ['0_' + col for col in transactions_dummies.columns]\n",
    "\n",
    "            transactions_dummies = transactions_dummies.groupby(transactions_dummies.index).sum()\n",
    "\n",
    "            transactions = transactions.drop(columns=[target_column]).join(transactions_dummies)\n",
    "        elif formatting == \"Sequential\":\n",
    "            #   client_id, sequence\n",
    "            #    C1,\"(bread,milk),(butter)\"\n",
    "            #    C2,\"(bread),(butter,cheese)\"\n",
    "            all_items = set()\n",
    "            parsed_sequences = []\n",
    "\n",
    "            for seq in transactions[target_column]:\n",
    "                all_transactions = re.findall(r\"\\((.*?)\\)\", seq)\n",
    "                steps = [t.split(\",\") for t in all_transactions]\n",
    "                steps = [[item.strip() for item in step if item.strip()] for step in steps]\n",
    "                parsed_sequences.append(steps)\n",
    "                for step in steps:\n",
    "                    all_items.update(step)\n",
    "\n",
    "            all_items = sorted(all_items)\n",
    "            print(all_items)\n",
    "            print(\"seq\", parsed_sequences)\n",
    "\n",
    "            output_rows = []\n",
    "\n",
    "            for i in range(len(transactions)):\n",
    "                client_id = transactions.loc[i, \"client_id\"]\n",
    "                steps = parsed_sequences[i]\n",
    "\n",
    "                row = {\"client_id\": client_id}\n",
    "                max_steps = len(steps)\n",
    "                for i in range(max_steps):\n",
    "                    for item in all_items:\n",
    "                        row[f\"{i}_{item}\"] = 1 if item in steps[i] else 0\n",
    "                output_rows.append(row)\n",
    "            transactions = pd.DataFrame(output_rows).fillna(0)\n",
    "        \n",
    "        # format encoded need nothing\n",
    "        return transactions\n",
    "\n",
    "    def load_transactions(self,file_path,header=True,target_column=None,sep=\",\",formatting=\"Basic\"):\n",
    "        \" Give pandas dataset of transaction \"\n",
    "        res = None\n",
    "        if file_path[-4:] == \".csv\":\n",
    "            try :\n",
    "                res = self.load_transaction_csv(file_path,header,target_column,sep,formatting)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error: {e}\")\n",
    "        \n",
    "        \n",
    "        if res is not None:\n",
    "            self.dfs.append(res)\n",
    "    \n",
    "    def displays(self):\n",
    "        for df in self.dfs:\n",
    "            display(df)\n",
    "    \n",
    "    def combine(self,indexes=[],column_to_check=None):\n",
    "        \"Combine 2 Databases given index [x,y] with a column to keep (transaction name), display database\"\n",
    "        if len(self.dfs) == 2:\n",
    "            indexes = [0,1]\n",
    "        elif (indexes == [] or max(indexes) >= len(self.dfs)) :\n",
    "            return\n",
    "        res = None\n",
    "        if column_to_check is not None:\n",
    "            # Merge using outer join to keep all names\n",
    "            df_merged = pd.merge(self.dfs[indexes[0]], self.dfs[indexes[1]], on=column_to_check, how='outer', suffixes=('_1', '_2'))\n",
    "\n",
    "            df_merged = df_merged.fillna(0)\n",
    "            numeric_cols = [c for c in df_merged.columns if c != column_to_check]\n",
    "            df_merged[numeric_cols] = df_merged[numeric_cols].astype(int)\n",
    "\n",
    "            # Combine columns with similar meaning\n",
    "            all_columns = set(self.dfs[indexes[0]].columns).union(self.dfs[indexes[1]].columns) - {column_to_check}\n",
    "            for col in all_columns:\n",
    "                # Find all columns corresponding to this original column (with _1/_2 suffixes or exact match)\n",
    "                cols_to_sum = [c for c in df_merged.columns if c == col or c.startswith(col + \"_\")]\n",
    "                if cols_to_sum:\n",
    "                    df_merged[col] = df_merged[cols_to_sum].sum(axis=1)\n",
    "                    if len(cols_to_sum) == 2: \n",
    "                        df_merged.drop(columns=cols_to_sum, inplace=True, errors='ignore')\n",
    "            res = df_merged\n",
    "            res = res[sorted(res.columns)]\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.dfs)\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "0e0fdf2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:52.579695Z",
     "start_time": "2025-11-23T14:44:52.540603Z"
    }
   },
   "source": [
    "T_df = TransactionDf('../data/stupid.csv',header=True,target_column=\"Articles\")\n",
    "T_df.displays()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Transaction  0_beurre  0_confiture  0_lait  0_pain\n",
       "0          T1         0            0       1       1\n",
       "1          T2         1            0       0       1\n",
       "2          T3         1            1       1       0\n",
       "3          T4         1            0       1       1\n",
       "4          T5         1            0       1       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "      <th>0_beurre</th>\n",
       "      <th>0_confiture</th>\n",
       "      <th>0_lait</th>\n",
       "      <th>0_pain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a73a5ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:52.636751Z",
     "start_time": "2025-11-23T14:44:52.622861Z"
    }
   },
   "source": [
    "T_df.load_transactions('../data/wide.csv',header=True,target_column=\"sequence\",formatting=\"Wide\")\n",
    "T_df.displays()\n",
    "#display(T_df.combine(column_to_check=\"Transaction\"))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Transaction  0_beurre  0_confiture  0_lait  0_pain\n",
       "0          T1         0            0       1       1\n",
       "1          T2         1            0       0       1\n",
       "2          T3         1            1       1       0\n",
       "3          T4         1            0       1       1\n",
       "4          T5         1            0       1       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "      <th>0_beurre</th>\n",
       "      <th>0_confiture</th>\n",
       "      <th>0_lait</th>\n",
       "      <th>0_pain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "                0_bread  0_butter  0_cheese  0_eggs  0_items  0_milk  0_yogurt\n",
       "transaction_id        0         0         0       0        1       0         0\n",
       "1                     1         0         0       1        0       1         0\n",
       "2                     1         1         0       0        0       0         0\n",
       "3                     0         1         1       0        0       1         0\n",
       "4                     1         1         0       0        0       1         0\n",
       "5                     1         0         0       1        0       0         0\n",
       "6                     0         0         1       0        0       1         1\n",
       "7                     1         1         0       1        0       1         0\n",
       "8                     0         0         1       0        0       0         1\n",
       "9                     1         1         0       1        0       0         0\n",
       "10                    1         0         1       0        0       1         1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_bread</th>\n",
       "      <th>0_butter</th>\n",
       "      <th>0_cheese</th>\n",
       "      <th>0_eggs</th>\n",
       "      <th>0_items</th>\n",
       "      <th>0_milk</th>\n",
       "      <th>0_yogurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "f3d0ee70",
   "metadata": {},
   "source": [
    "## Etape 1 : Extraction\n",
    "- Implémenter/adapter un algorithme de fouille exhaustive de données pour produire un pool P de motifs avec un seuil bas ; fournir\n",
    "pré-traitement et binarisation/agrégation.\n",
    "\n",
    "- Calculer pour chaque motif des métriques standard : support,\n",
    "confidence, lift, couverture, longueur.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c68a85bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:52.718918Z",
     "start_time": "2025-11-23T14:44:52.705579Z"
    }
   },
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Préparer le DataFrame pour fpgrowth :\n",
    "df_fp = T_df.dfs[0].copy()\n",
    "df_fp = df_fp.astype(bool)\n",
    "\n",
    "# Drop Transaction column\n",
    "if 'Transaction' in df_fp.columns:\n",
    "    df_fp = df_fp.drop(columns=['Transaction'])\n",
    "    \n",
    "print('Colonnes utilisées pour fpgrowth :', df_fp.columns.tolist())\n",
    "print(df_fp.head())\n",
    "\n",
    "\n",
    "# 1. Extraction des itemsets fréquents avec un seuil de support bas\n",
    "# TODO pouvoir mod le seuil sur UI\n",
    "min_support_seuil_bas = 0.33\n",
    "\n",
    "frequent_itemsets = fpgrowth(df_fp, min_support=min_support_seuil_bas, use_colnames=True)\n",
    "\n",
    "print(f\"\\nNombre d'itemsets fréquents trouvés (seuil bas) : {len(frequent_itemsets)}\")\n",
    "print(frequent_itemsets.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes utilisées pour fpgrowth : ['0_beurre', '0_confiture', '0_lait', '0_pain']\n",
      "   0_beurre  0_confiture  0_lait  0_pain\n",
      "0     False        False    True    True\n",
      "1      True        False   False    True\n",
      "2      True         True    True   False\n",
      "3      True        False    True    True\n",
      "4      True        False    True   False\n",
      "\n",
      "Nombre d'itemsets fréquents trouvés (seuil bas) : 6\n",
      "   support            itemsets\n",
      "0      0.8            (0_lait)\n",
      "1      0.6            (0_pain)\n",
      "2      0.8          (0_beurre)\n",
      "3      0.4    (0_pain, 0_lait)\n",
      "4      0.4  (0_pain, 0_beurre)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "f659e087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:52.753196Z",
     "start_time": "2025-11-23T14:44:52.744589Z"
    }
   },
   "source": [
    "# 2. Génération des règles d'association à partir des itemsets fréquents\n",
    "P_pool_rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
    "\n",
    "# Calcul des métriques\n",
    "P_pool_rules['length'] = P_pool_rules['antecedents'].apply(lambda x: len(x)) + P_pool_rules['consequents'].apply(lambda x: len(x))\n",
    "\n",
    "P_pool_rules.rename(columns={'antecedent support': 'coverage'}, inplace=True)\n",
    "\n",
    "cols_to_keep = ['antecedents', 'consequents', 'support', 'confidence', 'lift']\n",
    "if 'coverage' in P_pool_rules.columns:\n",
    "    cols_to_keep.append('coverage')\n",
    "    \n",
    "cols_to_keep.append('length')\n",
    "P_pool_rules = P_pool_rules[cols_to_keep]\n",
    "\n",
    "print(f\"Pool P de {len(P_pool_rules)} motifs (règles) généré :\")\n",
    "print(P_pool_rules)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool P de 6 motifs (règles) généré :\n",
      "  antecedents consequents  support  confidence      lift  coverage  length\n",
      "0    (0_pain)    (0_lait)      0.4    0.666667  0.833333       0.6       2\n",
      "1    (0_lait)    (0_pain)      0.4    0.500000  0.833333       0.8       2\n",
      "2    (0_pain)  (0_beurre)      0.4    0.666667  0.833333       0.6       2\n",
      "3  (0_beurre)    (0_pain)      0.4    0.500000  0.833333       0.8       2\n",
      "4  (0_beurre)    (0_lait)      0.6    0.750000  0.937500       0.8       2\n",
      "5    (0_lait)  (0_beurre)      0.6    0.750000  0.937500       0.8       2\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "40f15ff3",
   "metadata": {},
   "source": [
    "## Etape 2 : Échantillonnage interactif\n",
    "- Définir au moins une stratégie de scoring composite (ex. combinaison normalisée de support, lift, surprise, pénalité de redondance).\n",
    "- Implémenter un algorithme d’échantillonnage pondéré (importance\n",
    "sampling ou MCMC léger) paramétrable par l’utilisateur (taille k,\n",
    "remise/non-remise, ...).\n",
    "- Intégrer un mécanisme simple de feedback utilisateur (like/dislike)\n",
    "qui ré-pondère les motifs et permet une boucle interactive."
   ]
  },
  {
   "cell_type": "code",
   "id": "4bbbdf42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:54.199128Z",
     "start_time": "2025-11-23T14:44:52.759328Z"
    }
   },
   "source": [
    "# Définir au moins une stratégie de scoring composite (ex. combinaison normalisée de support, lift, surprise, pénalité de redondance).\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Copie du pool pour ne pas modifier l'original\n",
    "P_sampling = P_pool_rules.copy()\n",
    "\n",
    "# Normalisation des métriques (exemple : lift et confidence)\n",
    "metrics_to_normalize = ['lift', 'confidence']\n",
    "P_sampling[metrics_to_normalize] = scaler.fit_transform(P_sampling[metrics_to_normalize])\n",
    "\n",
    "# Définition d'un score composite simple (pondération 60% lift, 40% confidence)\n",
    "\n",
    "def composite_score(row, w_support = 0.2, w_lift = 0.2, w_conf = 0.2,  w_surprise = 0.2, w_redundancy_penalty = 0.2): # TODO: ajuster la formule selon les besoins / pouvoir changer le type de score sélectionné via UI\n",
    "    return w_lift * row['lift'] + w_conf * row['confidence'] + w_support * row['support'] + w_surprise * (1 - row['support']) - w_redundancy_penalty * (row['length'] / 10)\n",
    "P_sampling['composite_score'] = P_sampling.apply(composite_score, axis=1)\n",
    "\n",
    "# Ajout du poids de feedback (initialisé à 1) # TODO : intégrer feedback utilisateur réel via UI\n",
    "P_sampling['feedback_weight'] = 1.0\n",
    "\n",
    "# Le poids final pour l'échantillonnage sera (score * feedback)\n",
    "P_sampling['final_sampling_weight'] = P_sampling['composite_score'] * P_sampling['feedback_weight']\n",
    "\n",
    "\n",
    "print(\"\\nPool P avec scores composites et poids de feedback :\")\n",
    "print(P_sampling[['antecedents', 'consequents', 'composite_score', 'feedback_weight', 'final_sampling_weight']].head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pool P avec scores composites et poids de feedback :\n",
      "  antecedents consequents  composite_score  feedback_weight  \\\n",
      "0    (0_pain)    (0_lait)         0.293333              1.0   \n",
      "1    (0_lait)    (0_pain)         0.160000              1.0   \n",
      "2    (0_pain)  (0_beurre)         0.293333              1.0   \n",
      "3  (0_beurre)    (0_pain)         0.160000              1.0   \n",
      "4  (0_beurre)    (0_lait)         0.560000              1.0   \n",
      "\n",
      "   final_sampling_weight  \n",
      "0               0.293333  \n",
      "1               0.160000  \n",
      "2               0.293333  \n",
      "3               0.160000  \n",
      "4               0.560000  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "69bf5e98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:55.606894Z",
     "start_time": "2025-11-23T14:44:55.597616Z"
    }
   },
   "source": [
    "# Implémenter un algorithme d’échantillonnage pondéré (importance sampling ou MCMC léger) paramétrable par l’utilisateur (taille k, remise/non-remise, ...).\n",
    "import numpy as np\n",
    "\n",
    "# Proposal: index uniform\n",
    "# Acceptance: min(1, w_prop / w_cur) (similaire à Metropolis)\n",
    "# replace=True : renvoie k échantillons (avec répétition)\n",
    "# replace=False: renvoie k échantillons distincts (maximum max_iters itérations)\n",
    "def light_mcmc(P_df, k=10, replace=True, init_idx=None, max_iters=10000, random_state=None):\n",
    "   \n",
    "    weights = P_df['final_sampling_weight'].values.copy()\n",
    "    weights = np.maximum(weights, 0.0)\n",
    "    \n",
    "    # Si tous les poids sont nuls, utiliser des poids uniformes\n",
    "    if weights.sum() == 0:\n",
    "        weights = np.ones_like(weights)\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    n = len(weights)\n",
    "    if n == 0:\n",
    "        return P_df.copy()\n",
    "\n",
    "    if init_idx is None:\n",
    "        cur = int(rng.integers(n))\n",
    "    else:\n",
    "        cur = int(init_idx) % n\n",
    "\n",
    "    samples = []\n",
    "    visited = set()\n",
    "    iters = 0\n",
    "\n",
    "    while (len(samples) < k) and (iters < max_iters):\n",
    "        prop = int(rng.integers(n))\n",
    "        w_cur = weights[cur] if weights[cur] > 0 else 1e-12\n",
    "        w_prop = weights[prop] if weights[prop] > 0 else 1e-12\n",
    "        alpha = min(1.0, (w_prop / w_cur))\n",
    "        \n",
    "        if rng.random() < alpha:\n",
    "            cur = prop\n",
    "            \n",
    "        if replace:\n",
    "            samples.append(cur)\n",
    "        else:\n",
    "            if cur not in visited:\n",
    "                samples.append(cur)\n",
    "                visited.add(cur)\n",
    "        iters += 1\n",
    "\n",
    "    # Si on n'a pas réussi à collecter k échantillons distincts, compléter par un tirage pondéré sans replacement parmi les restants\n",
    "    if (not replace) and (len(samples) < k):\n",
    "        remaining = [i for i in range(n) if i not in set(samples)]\n",
    "        if remaining:\n",
    "            rem_weights = weights[remaining].astype(float)\n",
    "            rem_weights = np.maximum(rem_weights, 0.0)\n",
    "            if rem_weights.sum() == 0:\n",
    "                rem_probs = np.ones(len(remaining)) / len(remaining)\n",
    "            else:\n",
    "                rem_probs = rem_weights / rem_weights.sum()\n",
    "            need = k - len(samples)\n",
    "            chosen = rng.choice(remaining, size=min(need, len(remaining)), replace=False, p=rem_probs)\n",
    "            samples.extend(list(chosen))\n",
    "\n",
    "    \n",
    "    if len(samples) == 0:\n",
    "        raise Exception(\"Aucun échantillon n'a pu être collecté.\")\n",
    "    \n",
    "    # Return les lignes correspondant aux indices sélectionnés\n",
    "    return P_df.iloc[samples].reset_index(drop=True)\n",
    "\n",
    "print('Exemples MCMC léger\\n')\n",
    "\n",
    "res_replace = light_mcmc(P_sampling, k=5, replace=True, random_state=42)\n",
    "\n",
    "print('Avec remise :\\n')\n",
    "print(res_replace[['antecedents','consequents','final_sampling_weight']])\n",
    "\n",
    "res_no_replace = light_mcmc(P_sampling, k=5, replace=False, random_state=42)\n",
    "\n",
    "print('Sans remise (distincts) :\\n')\n",
    "print(res_no_replace[['antecedents','consequents','final_sampling_weight']])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples MCMC léger\n",
      "\n",
      "Avec remise :\n",
      "\n",
      "  antecedents consequents  final_sampling_weight\n",
      "0  (0_beurre)    (0_lait)                   0.56\n",
      "1  (0_beurre)    (0_lait)                   0.56\n",
      "2    (0_lait)  (0_beurre)                   0.56\n",
      "3    (0_lait)  (0_beurre)                   0.56\n",
      "4    (0_lait)  (0_beurre)                   0.56\n",
      "Sans remise (distincts) :\n",
      "\n",
      "  antecedents consequents  final_sampling_weight\n",
      "0  (0_beurre)    (0_lait)               0.560000\n",
      "1    (0_lait)  (0_beurre)               0.560000\n",
      "2    (0_pain)    (0_lait)               0.293333\n",
      "3  (0_beurre)    (0_pain)               0.160000\n",
      "4    (0_pain)  (0_beurre)               0.293333\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "da136acd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:55.661648Z",
     "start_time": "2025-11-23T14:44:55.654726Z"
    }
   },
   "source": [
    "P_sampling"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  antecedents consequents  support  confidence  lift  coverage  length  \\\n",
       "0    (0_pain)    (0_lait)      0.4    0.666667   0.0       0.6       2   \n",
       "1    (0_lait)    (0_pain)      0.4    0.000000   0.0       0.8       2   \n",
       "2    (0_pain)  (0_beurre)      0.4    0.666667   0.0       0.6       2   \n",
       "3  (0_beurre)    (0_pain)      0.4    0.000000   0.0       0.8       2   \n",
       "4  (0_beurre)    (0_lait)      0.6    1.000000   1.0       0.8       2   \n",
       "5    (0_lait)  (0_beurre)      0.6    1.000000   1.0       0.8       2   \n",
       "\n",
       "   composite_score  feedback_weight  final_sampling_weight  \n",
       "0         0.293333              1.0               0.293333  \n",
       "1         0.160000              1.0               0.160000  \n",
       "2         0.293333              1.0               0.293333  \n",
       "3         0.160000              1.0               0.160000  \n",
       "4         0.560000              1.0               0.560000  \n",
       "5         0.560000              1.0               0.560000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>coverage</th>\n",
       "      <th>length</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>feedback_weight</th>\n",
       "      <th>final_sampling_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.293333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.293333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "aff4de3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T14:44:55.685618Z",
     "start_time": "2025-11-23T14:44:55.673766Z"
    }
   },
   "source": [
    "# Intégrer un mécanisme simple de feedback utilisateur (like/dislike) qui ré-pondère les motifs et permet une boucle interactive.\n",
    "def _make_key(row):\n",
    "    return str(row['antecedents']) + '||' + str(row['consequents'])\n",
    "\n",
    "def apply_like(P_df, idx=None, key=None, factor=1.25):\n",
    "    # key : clé texte 'antecedents||consequents'\n",
    "    # ou idx : int\n",
    "    \n",
    "    if idx is not None:\n",
    "        P_df.at[int(idx), 'feedback_weight'] = float(factor)\n",
    "    elif key is not None:\n",
    "        mask = (P_df.apply(_make_key, axis=1) == key)\n",
    "        P_df.loc[mask, 'feedback_weight'] = P_df.loc[mask, 'feedback_weight'] * factor\n",
    "    P_df['final_sampling_weight'] = P_df['composite_score'] * P_df['feedback_weight']\n",
    "    return P_df\n",
    "\n",
    "def apply_dislike(P_df, idx=None, key=None, factor=0.8):\n",
    "    return apply_like(P_df, idx=idx, key=key, factor=factor)\n",
    "\n",
    "def reset_feedback(P_df):\n",
    "    P_df['feedback_weight'] = 1.0\n",
    "    P_df['final_sampling_weight'] = P_df['composite_score'].copy()\n",
    "    return P_df\n",
    "\n",
    "print('Exemple feedback programmatique :')\n",
    "\n",
    "print('Top avant feedback :')\n",
    "display(P_sampling.sort_values('final_sampling_weight', ascending=False).head(5)[['antecedents','consequents','final_sampling_weight','feedback_weight']])\n",
    "\n",
    "# simuler un like sur le motif ayant le plus grand poids actuel\n",
    "top_idx = P_sampling['final_sampling_weight'].idxmax()\n",
    "apply_like(P_sampling, idx=top_idx, factor=1.5)\n",
    "\n",
    "print('\\nTop après like multiplicatif sur le top 1 :')\n",
    "display(P_sampling.sort_values('final_sampling_weight', ascending=False).head(5)[['antecedents','consequents','final_sampling_weight','feedback_weight']])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple feedback programmatique :\n",
      "Top avant feedback :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  antecedents consequents  final_sampling_weight  feedback_weight\n",
       "4  (0_beurre)    (0_lait)               0.560000              1.0\n",
       "5    (0_lait)  (0_beurre)               0.560000              1.0\n",
       "0    (0_pain)    (0_lait)               0.293333              1.0\n",
       "2    (0_pain)  (0_beurre)               0.293333              1.0\n",
       "1    (0_lait)    (0_pain)               0.160000              1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>final_sampling_weight</th>\n",
       "      <th>feedback_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top après like multiplicatif sur le top 1 :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  antecedents consequents  final_sampling_weight  feedback_weight\n",
       "4  (0_beurre)    (0_lait)               0.840000              1.5\n",
       "5    (0_lait)  (0_beurre)               0.560000              1.0\n",
       "0    (0_pain)    (0_lait)               0.293333              1.0\n",
       "2    (0_pain)  (0_beurre)               0.293333              1.0\n",
       "1    (0_lait)    (0_pain)               0.160000              1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>final_sampling_weight</th>\n",
       "      <th>feedback_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>(0_beurre)</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0_lait)</td>\n",
       "      <td>(0_pain)</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
